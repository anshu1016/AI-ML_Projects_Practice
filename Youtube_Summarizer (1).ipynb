{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f28247267e449d995902add98b7aa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c61cceef4a2b4cb0a628b75e5f9092f0",
              "IPY_MODEL_7481a16a683b48c89accfb0f7962db58",
              "IPY_MODEL_3a1dfa257d3f46bb930a4b74d1e358e2"
            ],
            "layout": "IPY_MODEL_7baf6ca392f244658788e372fea571dc"
          }
        },
        "c61cceef4a2b4cb0a628b75e5f9092f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aa9c73c915645a694261225edcb307d",
            "placeholder": "​",
            "style": "IPY_MODEL_7ebf2607e1d04cca9a4fc4b13d2b174d",
            "value": "config.json: 100%"
          }
        },
        "7481a16a683b48c89accfb0f7962db58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47c468b184b4223b48374d045b39cba",
            "max": 892,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2878f77c65d1467abd0446bae2c66c46",
            "value": 892
          }
        },
        "3a1dfa257d3f46bb930a4b74d1e358e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010b43b5acbd4f4f9d0141e7458a65b3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6aedba32d584c6faf75fa3225b6bf11",
            "value": " 892/892 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "7baf6ca392f244658788e372fea571dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa9c73c915645a694261225edcb307d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ebf2607e1d04cca9a4fc4b13d2b174d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b47c468b184b4223b48374d045b39cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2878f77c65d1467abd0446bae2c66c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "010b43b5acbd4f4f9d0141e7458a65b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6aedba32d584c6faf75fa3225b6bf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0335f4f45d064e5f8be6c30906b09b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_246f53a301c4489f9c57eb9b3e39dd2f",
              "IPY_MODEL_06f6677a510e4e3ea8ba8e924461503e",
              "IPY_MODEL_b90413f88e564f00bf8b1190ea73ff58"
            ],
            "layout": "IPY_MODEL_f95a286d5cee46d690ca07b9e7c3b6cb"
          }
        },
        "246f53a301c4489f9c57eb9b3e39dd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e635752c03c04d789a3d94db9ed4e603",
            "placeholder": "​",
            "style": "IPY_MODEL_be36fdf359794409853347922373edc9",
            "value": "model.safetensors: 100%"
          }
        },
        "06f6677a510e4e3ea8ba8e924461503e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98df13d501d4bddbb77fc7ba58aad55",
            "max": 2235440664,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_716bf734344f48a5b6e9dc95c67422e0",
            "value": 2235440664
          }
        },
        "b90413f88e564f00bf8b1190ea73ff58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37aa2a4ef7bf42808949a6a09b93c8ef",
            "placeholder": "​",
            "style": "IPY_MODEL_12c2ecee99e44ee5a3bc024c2a9c2859",
            "value": " 2.24G/2.24G [00:41&lt;00:00, 36.1MB/s]"
          }
        },
        "f95a286d5cee46d690ca07b9e7c3b6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e635752c03c04d789a3d94db9ed4e603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be36fdf359794409853347922373edc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b98df13d501d4bddbb77fc7ba58aad55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716bf734344f48a5b6e9dc95c67422e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37aa2a4ef7bf42808949a6a09b93c8ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c2ecee99e44ee5a3bc024c2a9c2859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46d5e1caeff2445c964994c2947efd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d228e189c194afcacb0cc91d5b6590a",
              "IPY_MODEL_25149f858b234d3a9e85549f4e7df96a",
              "IPY_MODEL_5570700115fc4fb099846d69426791e5"
            ],
            "layout": "IPY_MODEL_34244121210d4b16a1fbb17106e45ed9"
          }
        },
        "1d228e189c194afcacb0cc91d5b6590a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3200ad14a30540f783876589634e84ba",
            "placeholder": "​",
            "style": "IPY_MODEL_a630d227f91b407aa72c4f98d3c4a7f6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "25149f858b234d3a9e85549f4e7df96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb15fe9bef13483e829d24c1900825d5",
            "max": 406,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51a62829951341539d51c4847c8561c7",
            "value": 406
          }
        },
        "5570700115fc4fb099846d69426791e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70b80539e2d8419e80205dc7153ddc32",
            "placeholder": "​",
            "style": "IPY_MODEL_f66d7d9671324ebf9cd6a69a2475173e",
            "value": " 406/406 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "34244121210d4b16a1fbb17106e45ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3200ad14a30540f783876589634e84ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a630d227f91b407aa72c4f98d3c4a7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb15fe9bef13483e829d24c1900825d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a62829951341539d51c4847c8561c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70b80539e2d8419e80205dc7153ddc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66d7d9671324ebf9cd6a69a2475173e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edec976832b3421cba338ac9c89cbc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcf24410353e434f8238696a3f57061c",
              "IPY_MODEL_e9c188086b56455489d3f4bb80bca832",
              "IPY_MODEL_4e7b8839a4f1473994f8116681ee830e"
            ],
            "layout": "IPY_MODEL_b1f4be52f26147ccbd6aa4f6a00702de"
          }
        },
        "fcf24410353e434f8238696a3f57061c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be26e1547e0547b886251b76086972a9",
            "placeholder": "​",
            "style": "IPY_MODEL_9c951720ae514d4a967b1814361b59d8",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "e9c188086b56455489d3f4bb80bca832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589610f2ece1472dbbee778ccad0b815",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06fb38dd7fb941cfb5fa41317387a1be",
            "value": 5069051
          }
        },
        "4e7b8839a4f1473994f8116681ee830e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca36c6506cd64863b8a5bef76465183a",
            "placeholder": "​",
            "style": "IPY_MODEL_49bfcb174fea4f8bb7a8fcf18dc187ec",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 8.43MB/s]"
          }
        },
        "b1f4be52f26147ccbd6aa4f6a00702de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be26e1547e0547b886251b76086972a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c951720ae514d4a967b1814361b59d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589610f2ece1472dbbee778ccad0b815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fb38dd7fb941cfb5fa41317387a1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca36c6506cd64863b8a5bef76465183a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49bfcb174fea4f8bb7a8fcf18dc187ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3616f9afddfd4c8c91bbc1a7592452d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb0903a9eb554ff288f5e99a62197adb",
              "IPY_MODEL_8833bc14b1624326be16687487640648",
              "IPY_MODEL_b09b565d3dd3416686afa1a85621540e"
            ],
            "layout": "IPY_MODEL_6f1609789eaf4266bc15a53c74a2ea7f"
          }
        },
        "bb0903a9eb554ff288f5e99a62197adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcb69b7947f4d10b463d776aa4bf283",
            "placeholder": "​",
            "style": "IPY_MODEL_b16dc4ab7c434886a722cd2814983c77",
            "value": "tokenizer.json: 100%"
          }
        },
        "8833bc14b1624326be16687487640648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f769c9fc17f8490f8a338c256904c065",
            "max": 17098080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f2f905ec3f24545a579f68509e301bd",
            "value": 17098080
          }
        },
        "b09b565d3dd3416686afa1a85621540e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9983a9b380c445cd98cf6a317b1452a5",
            "placeholder": "​",
            "style": "IPY_MODEL_96496008f76a438ea3d6bee4191bb5fa",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 28.5MB/s]"
          }
        },
        "6f1609789eaf4266bc15a53c74a2ea7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bcb69b7947f4d10b463d776aa4bf283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16dc4ab7c434886a722cd2814983c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f769c9fc17f8490f8a338c256904c065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2f905ec3f24545a579f68509e301bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9983a9b380c445cd98cf6a317b1452a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96496008f76a438ea3d6bee4191bb5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "237fcf581cbf4fcc9ad8c2c8057227fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd7c075a004a4b8297641d8f01ce4d33",
              "IPY_MODEL_4df27cc27aa14c08bbb3e3f17cb815f8",
              "IPY_MODEL_05b6090d9bfa4872b3af660894eb861c"
            ],
            "layout": "IPY_MODEL_2d359af6f4a84f8ebc74bca762c81ef1"
          }
        },
        "fd7c075a004a4b8297641d8f01ce4d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_072a8b41b81b47569004b9bc7b03067e",
            "placeholder": "​",
            "style": "IPY_MODEL_b4421c9794e44588ad17740c52f8d149",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4df27cc27aa14c08bbb3e3f17cb815f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c63a110553f4c9b83a0ca6f81f772d3",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20f788dea8694193810992c75de33f5c",
            "value": 239
          }
        },
        "05b6090d9bfa4872b3af660894eb861c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024b2879f714439eaf7bbd0e9a78ddd1",
            "placeholder": "​",
            "style": "IPY_MODEL_f3d52e9e054a460791671e8164828296",
            "value": " 239/239 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "2d359af6f4a84f8ebc74bca762c81ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072a8b41b81b47569004b9bc7b03067e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4421c9794e44588ad17740c52f8d149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c63a110553f4c9b83a0ca6f81f772d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f788dea8694193810992c75de33f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "024b2879f714439eaf7bbd0e9a78ddd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d52e9e054a460791671e8164828296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Youtube Video Transcript"
      ],
      "metadata": {
        "id": "Ogn4ceDY1HCL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWOKFs9lzsgg",
        "outputId": "10f73afd-f253-45a9-d3a2-d08b29cad67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.1.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.6.15)\n",
            "Downloading youtube_transcript_api-1.1.1-py3-none-any.whl (485 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/485.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.9/485.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.1.1\n"
          ]
        }
      ],
      "source": [
        "! pip install youtube_transcript_api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-1iAJK51f1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First way of splitting the link manually\n",
        "def get_video_id(url_link:str)->str:\n",
        "  return url_link.split('watch?v=')[1].split('&')[0]"
      ],
      "metadata": {
        "id": "XpeQNM1_-xdC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# second way to split the link using predefined library\n",
        "from urllib.parse import urlparse, parse_qs  # This imports Python tools that help you work with URLs.\n",
        "\n",
        "def get_video_id_2(url_link:str)->str:\n",
        "  query = urlparse(url_link).query   # urlparse(link) breaks the URL into parts. AND .query gives you the part after the ?, which is: v=xDQL3vWwcp0&list=someListId\n",
        "\n",
        "  params = parse_qs(query) # parse_qs(...) turns the query into a dictionary: {'v': ['xDQL3vWwcp0'], 'list': ['someListId']}\n",
        "  return params.get('v',[''])[0] # .get('v', ['']) tries to find the value for 'v' (video ID).\n",
        "  # \"If 'v' is not found in the dictionary, give me [''] as a default.\""
      ],
      "metadata": {
        "id": "PXppemVMAnkp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = get_video_id_2('https://www.youtube.com/watch?v=xDQL3vWwcp0&list=PL49M3zg4eCviRD4-hTjS5aUZs3PzAFYkJ&index=2')\n",
        "print(video_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKiZjdYt-7zW",
        "outputId": "7f74afe6-0efa-4e98-b27f-837f6c838df2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xDQL3vWwcp0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = YouTubeTranscriptApi.get_transcript(video_id)"
      ],
      "metadata": {
        "id": "aLObmUgc_I7L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcript) # we got a list of transcripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgCwp06aD-fm",
        "outputId": "ac73f827-f9a2-4d94-d047-8b065077a7f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': \"hello everyone I am Santi and I'm\", 'start': 0.16, 'duration': 3.559}, {'text': 'currently working as an ml engineer', 'start': 1.839, 'duration': 3.48}, {'text': 'today we are going to do an awesome', 'start': 3.719, 'duration': 3.241}, {'text': 'machine learning project that you can', 'start': 5.319, 'duration': 4.44}, {'text': 'add to your resume and impress all the', 'start': 6.96, 'duration': 4.92}, {'text': \"interviewers um I'm dedicated to\", 'start': 9.759, 'duration': 4.201}, {'text': 'teaching machine learning to all of you', 'start': 11.88, 'duration': 4.36}, {'text': 'and to ensure that you all learned an ml', 'start': 13.96, 'duration': 5.319}, {'text': 'job as soon as possible okay so without', 'start': 16.24, 'duration': 5.32}, {'text': \"any further Ado let's Dive Right\", 'start': 19.279, 'duration': 6.641}, {'text': 'In so our title is going to be um so our', 'start': 21.56, 'duration': 6.479}, {'text': 'project title is going to be uh YouTube', 'start': 25.92, 'duration': 4.88}, {'text': 'video summarizer with llm', 'start': 28.039, 'duration': 4.641}, {'text': \"well so what's going to do is going to\", 'start': 30.8, 'duration': 4.04}, {'text': 'take in a video and you can ask any', 'start': 32.68, 'duration': 4.0}, {'text': 'question regarding the videos contents', 'start': 34.84, 'duration': 4.64}, {'text': \"the images Etc and that's going to be\", 'start': 36.68, 'duration': 5.199}, {'text': 'really really good really useful as well', 'start': 39.48, 'duration': 4.12}, {'text': 'and that can be a mini deployed project', 'start': 41.879, 'duration': 5.561}, {'text': 'as well okay so first things first um', 'start': 43.6, 'duration': 5.92}, {'text': \"let's let's let's think about why do we\", 'start': 47.44, 'duration': 3.36}, {'text': 'need this in the first place the', 'start': 49.52, 'duration': 3.0}, {'text': 'interviewer might say why not just use', 'start': 50.8, 'duration': 4.64}, {'text': 'chat GPT right because chat gpg has now', 'start': 52.52, 'duration': 4.76}, {'text': 'enabled the search web feature for every', 'start': 55.44, 'duration': 3.799}, {'text': 'free user right so you might be', 'start': 57.28, 'duration': 4.32}, {'text': 'wondering why not just use that okay so', 'start': 59.239, 'duration': 3.921}, {'text': \"let's see why we are not going to use\", 'start': 61.6, 'duration': 3.72}, {'text': 'that as you can see right here we have', 'start': 63.16, 'duration': 6.12}, {'text': \"our chat GPT open and let's see um which\", 'start': 65.32, 'duration': 6.439}, {'text': 'video are we going to use yeah so this', 'start': 69.28, 'duration': 4.12}, {'text': 'is a video that we are going to use', 'start': 71.759, 'duration': 3.761}, {'text': 'right here as you can see my binary', 'start': 73.4, 'duration': 4.2}, {'text': 'classification video which is of the', 'start': 75.52, 'duration': 6.08}, {'text': \"length of 32 32 minutes okay so let's\", 'start': 77.6, 'duration': 6.36}, {'text': 'put this inside the chat GPD and I will', 'start': 81.6, 'duration': 6.28}, {'text': 'the search web feature and say write', 'start': 83.96, 'duration': 7.96}, {'text': 'the transcript for this', 'start': 87.88, 'duration': 4.04}, {'text': 'this for this video because first of all', 'start': 94.92, 'duration': 5.0}, {'text': \"we'll need the transcript\", 'start': 97.88, 'duration': 4.559}, {'text': 'right as you can see right', 'start': 99.92, 'duration': 5.32}, {'text': \"here it says that it's unable to\", 'start': 102.439, 'duration': 5.521}, {'text': 'actually get the video um transcript so', 'start': 105.24, 'duration': 3.919}, {'text': \"if you don't have the transcript\", 'start': 107.96, 'duration': 2.6}, {'text': \"obviously then you won't be able to do\", 'start': 109.159, 'duration': 3.481}, {'text': 'anything with it right okay whenever you', 'start': 110.56, 'duration': 4.159}, {'text': \"get any project it's very important to\", 'start': 112.64, 'duration': 3.519}, {'text': 'understand that you first need to break', 'start': 114.719, 'duration': 3.601}, {'text': 'the project down into smaller pieces', 'start': 116.159, 'duration': 4.0}, {'text': 'that you can tackle easily this is very', 'start': 118.32, 'duration': 3.6}, {'text': 'important because if you think that how', 'start': 120.159, 'duration': 3.481}, {'text': \"how am I going to do that we don't have\", 'start': 121.92, 'duration': 3.799}, {'text': \"this we don't have that at the first so\", 'start': 123.64, 'duration': 4.24}, {'text': \"this going to be very confusing so let's\", 'start': 125.719, 'duration': 4.281}, {'text': 'tackle it one by one step by step', 'start': 127.88, 'duration': 3.56}, {'text': 'remember this for any project that you', 'start': 130.0, 'duration': 3.2}, {'text': \"are going to do okay I'm going to use\", 'start': 131.44, 'duration': 4.2}, {'text': 'Google collab here because we need GPU', 'start': 133.2, 'duration': 4.2}, {'text': \"for our support so if you don't have GPU\", 'start': 135.64, 'duration': 3.2}, {'text': \"on your system or you're using any\", 'start': 137.4, 'duration': 3.68}, {'text': \"Windows system you're using a Mac system\", 'start': 138.84, 'duration': 3.84}, {'text': \"whatever it is it doesn't matter as long\", 'start': 141.08, 'duration': 3.239}, {'text': 'as you have Google collab you can just', 'start': 142.68, 'duration': 3.919}, {'text': \"go in it's free for you to use and you\", 'start': 144.319, 'duration': 4.441}, {'text': 'can do the project here and in your', 'start': 146.599, 'duration': 3.761}, {'text': 'resume you can just put in', 'start': 148.76, 'duration': 5.36}, {'text': \"link okay so let's do first install\", 'start': 150.36, 'duration': 5.12}, {'text': \"let's first install the YouTube\", 'start': 154.12, 'duration': 3.32}, {'text': 'transcript', 'start': 155.48, 'duration': 4.64}, {'text': 'API great now we have the YouTube trans', 'start': 157.44, 'duration': 5.0}, {'text': 'transcript API so now what we going to', 'start': 160.12, 'duration': 4.08}, {'text': 'do is basically get the link provide the', 'start': 162.44, 'duration': 4.96}, {'text': 'link to the video um to this library and', 'start': 164.2, 'duration': 5.399}, {'text': 'generate the transcript using', 'start': 167.4, 'duration': 4.24}, {'text': \"this now we're going to import the\", 'start': 169.599, 'duration': 3.521}, {'text': 'YouTube transcript', 'start': 171.64, 'duration': 4.36}, {'text': 'API so', 'start': 173.12, 'duration': 6.88}, {'text': 'from YouTube', 'start': 176.0, 'duration': 4.0}, {'text': 'YouTube transcript API sounds good now', 'start': 182.92, 'duration': 6.92}, {'text': \"let's get the video ID from the um video\", 'start': 186.599, 'duration': 5.0}, {'text': 'so what we going to do is basically as', 'start': 189.84, 'duration': 3.44}, {'text': 'you know this is the video right here', 'start': 191.599, 'duration': 3.801}, {'text': 'and this is the video ID so whenever you', 'start': 193.28, 'duration': 3.64}, {'text': \"put in a link you're going to get the\", 'start': 195.4, 'duration': 4.28}, {'text': 'video ID from here get video ID is going', 'start': 196.92, 'duration': 4.76}, {'text': 'to be this function great you now have', 'start': 199.68, 'duration': 4.68}, {'text': \"the video ID so let's see what the video\", 'start': 201.68, 'duration': 4.44}, {'text': 'ID looks', 'start': 204.36, 'duration': 4.079}, {'text': 'like', 'start': 206.12, 'duration': 5.64}, {'text': 'um copy', 'start': 208.439, 'duration': 3.321}, {'text': 'this yeah this is the video ID yeah next', 'start': 212.799, 'duration': 4.681}, {'text': 'thing is getting the transcript so', 'start': 215.84, 'duration': 4.08}, {'text': 'basically get video ID we already have', 'start': 217.48, 'duration': 5.2}, {'text': \"that so let's just store it in a\", 'start': 219.92, 'duration': 8.56}, {'text': 'variable this one going to be video', 'start': 222.68, 'duration': 5.8}, {'text': 'ID um', 'start': 229.959, 'duration': 5.761}, {'text': \"yeah sounds good now let's see what the\", 'start': 232.4, 'duration': 7.08}, {'text': 'transcript looks like', 'start': 235.72, 'duration': 3.76}, {'text': 'yeah as you can see this is what the', 'start': 240.92, 'duration': 3.159}, {'text': \"transcript looks like so now what you're\", 'start': 242.319, 'duration': 2.881}, {'text': 'going to do', 'start': 244.079, 'duration': 3.841}, {'text': 'is uh add all this', 'start': 245.2, 'duration': 5.72}, {'text': 'together yep yeah so now what we going', 'start': 247.92, 'duration': 5.679}, {'text': 'to do is do the transcript join so what', 'start': 250.92, 'duration': 5.36}, {'text': 'does it going to look', 'start': 253.599, 'duration': 5.561}, {'text': 'like exactly just join this together all', 'start': 256.28, 'duration': 5.72}, {'text': 'the text features that you have in this', 'start': 259.16, 'duration': 5.36}, {'text': 'transcript great now we can see what the', 'start': 262.0, 'duration': 6.639}, {'text': 'transcript joint looks like', 'start': 264.52, 'duration': 4.119}, {'text': 'yeah great as you can see right here', 'start': 270.32, 'duration': 6.68}, {'text': 'this is our transcript that we', 'start': 273.6, 'duration': 7.56}, {'text': 'have um okay as you can see we have it', 'start': 277.0, 'duration': 6.759}, {'text': \"Santi but we can't do anything about it\", 'start': 281.16, 'duration': 5.319}, {'text': \"so let's just forget about it for the\", 'start': 283.759, 'duration': 4.561}, {'text': 'moment', 'start': 286.479, 'duration': 5.361}, {'text': 'yeah um sounds good now what we going to', 'start': 288.32, 'duration': 5.04}, {'text': 'do is basically we need to as you can', 'start': 291.84, 'duration': 4.799}, {'text': 'see the transcript that you saw um it', 'start': 293.36, 'duration': 5.279}, {'text': 'does not actually have a proper', 'start': 296.639, 'duration': 3.521}, {'text': 'punctuation so we going to put in the', 'start': 298.639, 'duration': 3.641}, {'text': \"punctuation now how we're going to do\", 'start': 300.16, 'duration': 4.759}, {'text': \"that we're going to use a model for that\", 'start': 302.28, 'duration': 4.04}, {'text': 'this is where the llm comes into the', 'start': 304.919, 'duration': 3.361}, {'text': 'play okay so now as you can see like uh', 'start': 306.32, 'duration': 3.8}, {'text': 'restoring the punctuation this is called', 'start': 308.28, 'duration': 4.199}, {'text': 'a library which we have actually and', 'start': 310.12, 'duration': 4.44}, {'text': 'this is actually a restore Punk Library', 'start': 312.479, 'duration': 3.72}, {'text': 'yeah this is our Punk library that we', 'start': 314.56, 'duration': 3.72}, {'text': \"have actually but there's a problem out\", 'start': 316.199, 'duration': 4.28}, {'text': 'here the versions are very like old', 'start': 318.28, 'duration': 3.759}, {'text': \"because it's three years ago so that is\", 'start': 320.479, 'duration': 3.641}, {'text': \"why there's a patch for the Same by\", 'start': 322.039, 'duration': 4.561}, {'text': 'another uh GitHub user so that that is', 'start': 324.12, 'duration': 4.919}, {'text': 'what we are going to use here great so', 'start': 326.6, 'duration': 4.039}, {'text': 'this is actually the thing please note', 'start': 329.039, 'duration': 3.201}, {'text': \"it down because you're going to need\", 'start': 330.639, 'duration': 3.881}, {'text': \"this if you use the normal ARB it's not\", 'start': 332.24, 'duration': 4.519}, {'text': 'going to help great now the next thing', 'start': 334.52, 'duration': 4.6}, {'text': 'comes is restoring the punctuations so', 'start': 336.759, 'duration': 3.801}, {'text': 'from the r pun we going to import', 'start': 339.12, 'duration': 2.96}, {'text': \"restore puns and then you're going to\", 'start': 340.56, 'duration': 3.88}, {'text': 'use this restore Punk function so what', 'start': 342.08, 'duration': 4.28}, {'text': 'this actually does behind the scenes is', 'start': 344.44, 'duration': 4.52}, {'text': 'it uses a model from the hugging face', 'start': 346.36, 'duration': 4.679}, {'text': 'library and this model is actually', 'start': 348.96, 'duration': 4.32}, {'text': 'loaded here and this model is actually', 'start': 351.039, 'duration': 5.961}, {'text': 'pre-trained for taking in bunch of text', 'start': 353.28, 'duration': 6.72}, {'text': 'and then um getting the punctu ation', 'start': 357.0, 'duration': 5.36}, {'text': 'back to that text great now that this is', 'start': 360.0, 'duration': 5.12}, {'text': \"done let's move on to the um getting the\", 'start': 362.36, 'duration': 5.16}, {'text': 'results from the punctuation so as you', 'start': 365.12, 'duration': 4.44}, {'text': 'can see right here this one py toch', 'start': 367.52, 'duration': 5.2}, {'text': 'model this model actually got loaded so', 'start': 369.56, 'duration': 4.759}, {'text': 'one thing if you facing some problem', 'start': 372.72, 'duration': 4.36}, {'text': \"with GPU it's very important to use this\", 'start': 374.319, 'duration': 6.521}, {'text': 'actually um here yeah as you can see', 'start': 377.08, 'duration': 6.8}, {'text': 'right here we have GPU enable T4 so you', 'start': 380.84, 'duration': 5.84}, {'text': 'need to enable the GPU in your um collab', 'start': 383.88, 'duration': 4.24}, {'text': \"otherwise you're going to get an error\", 'start': 386.68, 'duration': 3.639}, {'text': \"that is GPU is not available and it's\", 'start': 388.12, 'duration': 4.0}, {'text': 'not really possible to do this without', 'start': 390.319, 'duration': 4.16}, {'text': 'GPU you can do it with CPU as well but', 'start': 392.12, 'duration': 4.76}, {'text': \"it's going to be very slow okay so now\", 'start': 394.479, 'duration': 3.56}, {'text': 'that you can see we have loaded the', 'start': 396.88, 'duration': 3.159}, {'text': 'model we have gotten all this vocabulary', 'start': 398.039, 'duration': 3.6}, {'text': 'we have gotten the tokenizer we have', 'start': 400.039, 'duration': 4.0}, {'text': 'gotten the configuration and everything', 'start': 401.639, 'duration': 5.0}, {'text': \"so now we are ready to go let's see the\", 'start': 404.039, 'duration': 4.6}, {'text': 'results yeah we are printing out the', 'start': 406.639, 'duration': 4.081}, {'text': 'results as you can see yeah this is as', 'start': 408.639, 'duration': 3.96}, {'text': \"you can see it's like very good\", 'start': 410.72, 'duration': 4.24}, {'text': \"punctuation I'm an algorithm full stop\", 'start': 412.599, 'duration': 4.081}, {'text': \"I've covered log likelihood it which is\", 'start': 414.96, 'duration': 3.56}, {'text': 'kind of a prerequisite full stop then', 'start': 416.68, 'duration': 5.199}, {'text': \"comma a du let start it's pretty good\", 'start': 418.52, 'duration': 6.16}, {'text': \"not um 100% accurate because it's not a\", 'start': 421.879, 'duration': 5.0}, {'text': \"very good model but it's pretty good we\", 'start': 424.68, 'duration': 4.519}, {'text': 'are going to use this okay so the next', 'start': 426.879, 'duration': 5.04}, {'text': \"thing that we're going to do is um we're\", 'start': 429.199, 'duration': 4.881}, {'text': 'going to use the chat GPT free version', 'start': 431.919, 'duration': 5.441}, {'text': 'API version to get the results from this', 'start': 434.08, 'duration': 5.04}, {'text': 'transcript so as you can see we have the', 'start': 437.36, 'duration': 3.04}, {'text': 'transcript right here so we know the', 'start': 439.12, 'duration': 3.16}, {'text': \"entire content of the video so it's\", 'start': 440.4, 'duration': 3.6}, {'text': 'going to be piece of cake for now sounds', 'start': 442.28, 'duration': 3.52}, {'text': \"good yeah so let's see we going to\", 'start': 444.0, 'duration': 3.52}, {'text': 'import open', 'start': 445.8, 'duration': 4.0}, {'text': \"AI as you can see I've already install\", 'start': 447.52, 'duration': 3.84}, {'text': 'open a if you have not then you can do', 'start': 449.8, 'duration': 3.679}, {'text': 'it using not equal to pip install open', 'start': 451.36, 'duration': 5.399}, {'text': 'AI to the open AI API key', 'start': 453.479, 'duration': 5.601}, {'text': 'website yeah as you can see right here', 'start': 456.759, 'duration': 5.44}, {'text': 'this has API key you can just log in', 'start': 459.08, 'duration': 4.72}, {'text': \"yeah you can just log in here's my API\", 'start': 462.199, 'duration': 3.081}, {'text': \"key you can't see that just create a new\", 'start': 463.8, 'duration': 4.04}, {'text': 'secret key write the key permissions all', 'start': 465.28, 'duration': 4.12}, {'text': 'create secret key and you have the API', 'start': 467.84, 'duration': 3.639}, {'text': \"key right here it's a it's it's very\", 'start': 469.4, 'duration': 4.759}, {'text': 'easy sounds good now now we have the API', 'start': 471.479, 'duration': 4.44}, {'text': 'key now we are having the', 'start': 474.159, 'duration': 4.48}, {'text': \"prompt so let's have the prompt here so\", 'start': 475.919, 'duration': 4.201}, {'text': \"as you can see right here let's go over\", 'start': 478.639, 'duration': 3.96}, {'text': 'this so from open we importing open then', 'start': 480.12, 'duration': 4.519}, {'text': 'we have the client with the API key just', 'start': 482.599, 'duration': 4.28}, {'text': 'now we set and now this is the remember', 'start': 484.639, 'duration': 3.721}, {'text': 'this this is very very easy and this is', 'start': 486.879, 'duration': 3.04}, {'text': 'like very standard thing that we going', 'start': 488.36, 'duration': 3.239}, {'text': 'to do so this is the way you have to', 'start': 489.919, 'duration': 4.601}, {'text': 'access the uh openai API so we have the', 'start': 491.599, 'duration': 5.32}, {'text': 'message here roll user content prompt so', 'start': 494.52, 'duration': 3.799}, {'text': 'this is the prompt that we going to pass', 'start': 496.919, 'duration': 3.801}, {'text': 'in um and then we are going to use a', 'start': 498.319, 'duration': 4.521}, {'text': 'model GPT 3.5 turbo because the other', 'start': 500.72, 'duration': 4.12}, {'text': \"GPD models are all paid we're not going\", 'start': 502.84, 'duration': 3.319}, {'text': \"to use a paid version we're going to use\", 'start': 504.84, 'duration': 3.079}, {'text': 'the free version and we have the', 'start': 506.159, 'duration': 3.961}, {'text': 'temperature set equal to one it controls', 'start': 507.919, 'duration': 4.8}, {'text': 'a Randomness basically Max tokens 2 56', 'start': 510.12, 'duration': 5.039}, {'text': 'is the maximum number of tokens in the', 'start': 512.719, 'duration': 5.12}, {'text': 'response um top P equal to 1 which means', 'start': 515.159, 'duration': 4.601}, {'text': 'the op is a nuclear sampling parameter', 'start': 517.839, 'duration': 4.12}, {'text': 'which is just another thing for uh like', 'start': 519.76, 'duration': 4.6}, {'text': 'temperature just like temperature we we', 'start': 521.959, 'duration': 3.88}, {'text': 'are determining the one with the higher', 'start': 524.36, 'duration': 5.12}, {'text': 'probability Mass um frequency penalty is', 'start': 525.839, 'duration': 5.68}, {'text': \"basically zero which means that we don't\", 'start': 529.48, 'duration': 4.64}, {'text': 'want the model to repeat anything and', 'start': 531.519, 'duration': 4.241}, {'text': 'prence penalty is also zero which means', 'start': 534.12, 'duration': 2.92}, {'text': 'that we do not want it to add', 'start': 535.76, 'duration': 3.68}, {'text': 'unnecessary words or just making it for', 'start': 537.04, 'duration': 3.96}, {'text': 'veros without any reason for example if', 'start': 539.44, 'duration': 3.079}, {'text': \"you're asking for one word just reply\", 'start': 541.0, 'duration': 4.36}, {'text': \"with one word don't be any like verbos\", 'start': 542.519, 'duration': 4.681}, {'text': \"and explain why you're saying that and\", 'start': 545.36, 'duration': 4.84}, {'text': \"all that you don't want that right um so\", 'start': 547.2, 'duration': 4.199}, {'text': \"let's run\", 'start': 550.2, 'duration': 3.4}, {'text': 'this great now we have the response', 'start': 551.399, 'duration': 3.88}, {'text': 'right here simple thing just print it', 'start': 553.6, 'duration': 3.44}, {'text': 'out so this is the way you can print out', 'start': 555.279, 'duration': 3.721}, {'text': 'the response is very important chat', 'start': 557.04, 'duration': 4.68}, {'text': 'completion. choices z. message. content', 'start': 559.0, 'duration': 4.64}, {'text': 'this is the way it actually comes in so', 'start': 561.72, 'duration': 3.2}, {'text': 'if you want to see what the chat', 'start': 563.64, 'duration': 2.8}, {'text': 'completion looks like you can check it', 'start': 564.92, 'duration': 3.8}, {'text': \"out it's actually kind of a dictionary\", 'start': 566.44, 'duration': 4.28}, {'text': \"uh it's kind of a class here where you\", 'start': 568.72, 'duration': 4.32}, {'text': 'have different attributes so this is the', 'start': 570.72, 'duration': 4.84}, {'text': 'content that we want um so that is why', 'start': 573.04, 'duration': 4.56}, {'text': \"we are doing this so let's see the\", 'start': 575.56, 'duration': 3.399}, {'text': 'content so the test discusses the', 'start': 577.6, 'duration': 3.08}, {'text': 'derivation and maths focusing on binary', 'start': 578.959, 'duration': 4.681}, {'text': 'classification perfect destion boundary', 'start': 580.68, 'duration': 4.719}, {'text': 'uh like likelihood function sigmoid', 'start': 583.64, 'duration': 4.199}, {'text': 'function gradient descent optimal', 'start': 585.399, 'duration': 4.12}, {'text': 'parameters like Theta it controls by', 'start': 587.839, 'duration': 3.801}, {'text': 'discussing how to determine the equation', 'start': 589.519, 'duration': 4.121}, {'text': 'in theeta transpose X comprehensive', 'start': 591.64, 'duration': 3.92}, {'text': 'explanation and its implementation so', 'start': 593.64, 'duration': 4.759}, {'text': \"well it's your cue to go and study this\", 'start': 595.56, 'duration': 6.12}, {'text': 'classification um video as well but yeah', 'start': 598.399, 'duration': 4.761}, {'text': \"you can do it at your own pace but it's\", 'start': 601.68, 'duration': 3.88}, {'text': 'a very important thing as well sorry not', 'start': 603.16, 'duration': 4.64}, {'text': 'sorry a little bit of promotion but yeah', 'start': 605.56, 'duration': 4.2}, {'text': 'now we done so now you can just take on', 'start': 607.8, 'duration': 4.52}, {'text': 'a prompt which is any kind of prompt', 'start': 609.76, 'duration': 4.639}, {'text': \"that you want uh why don't why just\", 'start': 612.32, 'duration': 5.36}, {'text': \"change this let's just have this one\", 'start': 614.399, 'duration': 5.801}, {'text': \"right here so let's change it to I don't\", 'start': 617.68, 'duration': 4.44}, {'text': 'know anything you want', 'start': 620.2, 'duration': 5.759}, {'text': 'maybe um', 'start': 622.12, 'duration': 3.839}, {'text': 'answer questions based on', 'start': 626.44, 'duration': 5.959}, {'text': \"this text you have right here so let's\", 'start': 629.959, 'duration': 5.68}, {'text': 'add a question um what do you want me to', 'start': 632.399, 'duration': 5.841}, {'text': \"add let's\", 'start': 635.639, 'duration': 6.44}, {'text': 'say what is', 'start': 638.24, 'duration': 3.839}, {'text': 'classification what is exactly taught', 'start': 644.6, 'duration': 4.32}, {'text': \"here let's see what it has to say\", 'start': 649.48, 'duration': 6.359}, {'text': 'algorithm predict the class speaker well', 'start': 653.16, 'duration': 4.56}, {'text': \"it's not my name but whatever we have\", 'start': 655.839, 'duration': 4.12}, {'text': 'put it in the transcript so derivation', 'start': 657.72, 'duration': 3.96}, {'text': 'and math specifically binary', 'start': 659.959, 'duration': 4.12}, {'text': 'classification uh okay my gender is also', 'start': 661.68, 'duration': 5.279}, {'text': 'wrong but whatever decision boundary and', 'start': 664.079, 'duration': 5.241}, {'text': 'then dering the this one radiant descent', 'start': 666.959, 'duration': 4.841}, {'text': 'see is perfect the answer is perfect key', 'start': 669.32, 'duration': 4.92}, {'text': 'Concepts it um and steps involving', 'start': 671.8, 'duration': 4.2}, {'text': 'binary classification retailed', 'start': 674.24, 'duration': 3.2}, {'text': 'description as you can see this is', 'start': 676.0, 'duration': 3.48}, {'text': 'extremely good um I also show you how', 'start': 677.44, 'duration': 3.519}, {'text': 'you can deploy this from n to end but', 'start': 679.48, 'duration': 3.84}, {'text': \"that's for another video okay take care\", 'start': 680.959, 'duration': 4.801}, {'text': 'bye', 'start': 683.32, 'duration': 2.44}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[line['text'] for line in transcript]\n",
        "Means:\n",
        "\n",
        "Go through each line in the transcript and collect only the line['text'] part.\n",
        "\n",
        "Result:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "['Hello and welcome', 'Today we learn Python', 'Let’s get started']"
      ],
      "metadata": {
        "id": "hgkOFKmWE12_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the transcript , make it paragraph\n",
        "transcript_joined = \" \".join([line['text'] for line in transcript])"
      ],
      "metadata": {
        "id": "UYpIJT4GEE1K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_joined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "K8tl0N61EgB5",
        "outputId": "de01a34c-d8a6-4bf1-992f-e27716f70cc0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hello everyone I am Santi and I'm currently working as an ml engineer today we are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers um I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an ml job as soon as possible okay so without any further Ado let's Dive Right In so our title is going to be um so our project title is going to be uh YouTube video summarizer with llm well so what's going to do is going to take in a video and you can ask any question regarding the videos contents the images Etc and that's going to be really really good really useful as well and that can be a mini deployed project as well okay so first things first um let's let's let's think about why do we need this in the first place the interviewer might say why not just use chat GPT right because chat gpg has now enabled the search web feature for every free user right so you might be wondering why not just use that okay so let's see why we are not going to use that as you can see right here we have our chat GPT open and let's see um which video are we going to use yeah so this is a video that we are going to use right here as you can see my binary classification video which is of the length of 32 32 minutes okay so let's put this inside the chat GPD and I will the search web feature and say write the transcript for this this for this video because first of all we'll need the transcript right as you can see right here it says that it's unable to actually get the video um transcript so if you don't have the transcript obviously then you won't be able to do anything with it right okay whenever you get any project it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily this is very important because if you think that how how am I going to do that we don't have this we don't have that at the first so this going to be very confusing so let's tackle it one by one step by step remember this for any project that you are going to do okay I'm going to use Google collab here because we need GPU for our support so if you don't have GPU on your system or you're using any Windows system you're using a Mac system whatever it is it doesn't matter as long as you have Google collab you can just go in it's free for you to use and you can do the project here and in your resume you can just put in link okay so let's do first install let's first install the YouTube transcript API great now we have the YouTube trans transcript API so now what we going to do is basically get the link provide the link to the video um to this library and generate the transcript using this now we're going to import the YouTube transcript API so from YouTube YouTube transcript API sounds good now let's get the video ID from the um video so what we going to do is basically as you know this is the video right here and this is the video ID so whenever you put in a link you're going to get the video ID from here get video ID is going to be this function great you now have the video ID so let's see what the video ID looks like um copy this yeah this is the video ID yeah next thing is getting the transcript so basically get video ID we already have that so let's just store it in a variable this one going to be video ID um yeah sounds good now let's see what the transcript looks like yeah as you can see this is what the transcript looks like so now what you're going to do is uh add all this together yep yeah so now what we going to do is do the transcript join so what does it going to look like exactly just join this together all the text features that you have in this transcript great now we can see what the transcript joint looks like yeah great as you can see right here this is our transcript that we have um okay as you can see we have it Santi but we can't do anything about it so let's just forget about it for the moment yeah um sounds good now what we going to do is basically we need to as you can see the transcript that you saw um it does not actually have a proper punctuation so we going to put in the punctuation now how we're going to do that we're going to use a model for that this is where the llm comes into the play okay so now as you can see like uh restoring the punctuation this is called a library which we have actually and this is actually a restore Punk Library yeah this is our Punk library that we have actually but there's a problem out here the versions are very like old because it's three years ago so that is why there's a patch for the Same by another uh GitHub user so that that is what we are going to use here great so this is actually the thing please note it down because you're going to need this if you use the normal ARB it's not going to help great now the next thing comes is restoring the punctuations so from the r pun we going to import restore puns and then you're going to use this restore Punk function so what this actually does behind the scenes is it uses a model from the hugging face library and this model is actually loaded here and this model is actually pre-trained for taking in bunch of text and then um getting the punctu ation back to that text great now that this is done let's move on to the um getting the results from the punctuation so as you can see right here this one py toch model this model actually got loaded so one thing if you facing some problem with GPU it's very important to use this actually um here yeah as you can see right here we have GPU enable T4 so you need to enable the GPU in your um collab otherwise you're going to get an error that is GPU is not available and it's not really possible to do this without GPU you can do it with CPU as well but it's going to be very slow okay so now that you can see we have loaded the model we have gotten all this vocabulary we have gotten the tokenizer we have gotten the configuration and everything so now we are ready to go let's see the results yeah we are printing out the results as you can see yeah this is as you can see it's like very good punctuation I'm an algorithm full stop I've covered log likelihood it which is kind of a prerequisite full stop then comma a du let start it's pretty good not um 100% accurate because it's not a very good model but it's pretty good we are going to use this okay so the next thing that we're going to do is um we're going to use the chat GPT free version API version to get the results from this transcript so as you can see we have the transcript right here so we know the entire content of the video so it's going to be piece of cake for now sounds good yeah so let's see we going to import open AI as you can see I've already install open a if you have not then you can do it using not equal to pip install open AI to the open AI API key website yeah as you can see right here this has API key you can just log in yeah you can just log in here's my API key you can't see that just create a new secret key write the key permissions all create secret key and you have the API key right here it's a it's it's very easy sounds good now now we have the API key now we are having the prompt so let's have the prompt here so as you can see right here let's go over this so from open we importing open then we have the client with the API key just now we set and now this is the remember this this is very very easy and this is like very standard thing that we going to do so this is the way you have to access the uh openai API so we have the message here roll user content prompt so this is the prompt that we going to pass in um and then we are going to use a model GPT 3.5 turbo because the other GPD models are all paid we're not going to use a paid version we're going to use the free version and we have the temperature set equal to one it controls a Randomness basically Max tokens 2 56 is the maximum number of tokens in the response um top P equal to 1 which means the op is a nuclear sampling parameter which is just another thing for uh like temperature just like temperature we we are determining the one with the higher probability Mass um frequency penalty is basically zero which means that we don't want the model to repeat anything and prence penalty is also zero which means that we do not want it to add unnecessary words or just making it for veros without any reason for example if you're asking for one word just reply with one word don't be any like verbos and explain why you're saying that and all that you don't want that right um so let's run this great now we have the response right here simple thing just print it out so this is the way you can print out the response is very important chat completion. choices z. message. content this is the way it actually comes in so if you want to see what the chat completion looks like you can check it out it's actually kind of a dictionary uh it's kind of a class here where you have different attributes so this is the content that we want um so that is why we are doing this so let's see the content so the test discusses the derivation and maths focusing on binary classification perfect destion boundary uh like likelihood function sigmoid function gradient descent optimal parameters like Theta it controls by discussing how to determine the equation in theeta transpose X comprehensive explanation and its implementation so well it's your cue to go and study this classification um video as well but yeah you can do it at your own pace but it's a very important thing as well sorry not sorry a little bit of promotion but yeah now we done so now you can just take on a prompt which is any kind of prompt that you want uh why don't why just change this let's just have this one right here so let's change it to I don't know anything you want maybe um answer questions based on this text you have right here so let's add a question um what do you want me to add let's say what is classification what is exactly taught here let's see what it has to say algorithm predict the class speaker well it's not my name but whatever we have put it in the transcript so derivation and math specifically binary classification uh okay my gender is also wrong but whatever decision boundary and then dering the this one radiant descent see is perfect the answer is perfect key Concepts it um and steps involving binary classification retailed description as you can see this is extremely good um I also show you how you can deploy this from n to end but that's for another video okay take care bye\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no punctuation, so its just a words. So to make it meaningful paragraph we need to pu punctation. For this we use rpunct library"
      ],
      "metadata": {
        "id": "yxrt6T6AE6CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/babthamotharan/rpunct.git@patch-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dG1V7X25E492",
        "outputId": "a0d078be-0b74-473e-afa3-7f06bc7ad3ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/babthamotharan/rpunct.git@patch-2\n",
            "  Cloning https://github.com/babthamotharan/rpunct.git (to revision patch-2) to /tmp/pip-req-build-6mmwv7nu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/babthamotharan/rpunct.git /tmp/pip-req-build-6mmwv7nu\n",
            "  Running command git checkout -b patch-2 --track origin/patch-2\n",
            "  Switched to a new branch 'patch-2'\n",
            "  Branch 'patch-2' set up to track remote branch 'patch-2' from 'origin'.\n",
            "  Resolved https://github.com/babthamotharan/rpunct.git to commit a87b93410ca782657abb4e34df9159e6e47ac9ec\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect>=1.0.9 (from rpunct==1.0.2)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from rpunct==1.0.2) (2.2.2)\n",
            "Collecting simpletransformers>=0.61.4 (from rpunct==1.0.2)\n",
            "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from rpunct==1.0.2) (1.17.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from rpunct==1.0.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.67.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2024.11.6)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.53.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.14.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (1.6.1)\n",
            "Collecting seqeval (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.18.0)\n",
            "Collecting tensorboardx (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.21.2)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.21.0)\n",
            "Collecting streamlit (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.1->rpunct==1.0.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->rpunct==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (0.33.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (0.5.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.32.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (2025.6.15)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (3.11.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->rpunct==1.0.2) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->simpletransformers>=0.61.4->rpunct==1.0.2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->simpletransformers>=0.61.4->rpunct==1.0.2) (3.6.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (5.5.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (11.2.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (6.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (3.8.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (1.45.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.20.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.4.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.26.0)\n",
            "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rpunct, langdetect, seqeval\n",
            "  Building wheel for rpunct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpunct: filename=rpunct-1.0.2-py3-none-any.whl size=5887 sha256=a73d16250ad0cd2108c893e86a10e4dc30356b452677838c02f31e56f8114672\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8e82qawa/wheels/be/5b/6a/bc4b174e97ac0584ce55ca312be4310c1e76ed17db89e8dc32\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=9c55cf23d8bdb4d7ff91bb6a87ec08e3696d3ada77dacd616276689563fd1d48\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=7b068bd1c527995b93e88c9efcd5f6f2579cf81690d92b22efec15f7a5278816\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built rpunct langdetect seqeval\n",
            "Installing collected packages: watchdog, tensorboardx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, seqeval, nvidia-cusolver-cu12, streamlit, simpletransformers, rpunct\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed langdetect-1.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydeck-0.9.1 rpunct-1.0.2 seqeval-1.2.2 simpletransformers-0.70.1 streamlit-1.46.1 tensorboardx-2.6.4 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does it do behind the scenes:\n",
        "It uses the hugging face model afrom the library and that model is pretrained in taking bunch of textx and put the punctuations"
      ],
      "metadata": {
        "id": "TPADX-ZlF8E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rpunct import RestorePuncts\n",
        "rpunct = RestorePuncts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "Vg2xB0mkFXl_",
        "outputId": "905d0601-f037-469b-f5dd-c6235fbc0448"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'DummyObject' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-2096919438.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrpunct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRestorePuncts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrpunct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRestorePuncts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rpunct/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpunctuate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRestorePuncts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rpunct/punctuate.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNERModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/simpletransformers/ner/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNERArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNERModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/simpletransformers/ner/ner_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyObject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DummyObject' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why This Happens\n",
        "rpunct internally uses simpletransformers\n",
        "\n",
        "simpletransformers expects transformers to have DummyObject, which was removed in newer versions\n",
        "\n",
        "So you need to stick to an older transformers version that still supports it\n",
        "\n",
        "\n",
        "### So we are using other model"
      ],
      "metadata": {
        "id": "nNeAB4X-HTkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deepmultilingualpunctuation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu6ys9OIGarO",
        "outputId": "b61e9f39-cd0f-4ec2-e721-585a2043259a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepmultilingualpunctuation\n",
            "  Downloading deepmultilingualpunctuation-1.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from deepmultilingualpunctuation) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from deepmultilingualpunctuation) (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->deepmultilingualpunctuation) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->deepmultilingualpunctuation) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->deepmultilingualpunctuation) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->deepmultilingualpunctuation) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->deepmultilingualpunctuation) (2025.6.15)\n",
            "Downloading deepmultilingualpunctuation-1.0.1-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: deepmultilingualpunctuation\n",
            "Successfully installed deepmultilingualpunctuation-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "\n",
        "# Load model\n",
        "model = PunctuationModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "7f28247267e449d995902add98b7aa6e",
            "c61cceef4a2b4cb0a628b75e5f9092f0",
            "7481a16a683b48c89accfb0f7962db58",
            "3a1dfa257d3f46bb930a4b74d1e358e2",
            "7baf6ca392f244658788e372fea571dc",
            "9aa9c73c915645a694261225edcb307d",
            "7ebf2607e1d04cca9a4fc4b13d2b174d",
            "b47c468b184b4223b48374d045b39cba",
            "2878f77c65d1467abd0446bae2c66c46",
            "010b43b5acbd4f4f9d0141e7458a65b3",
            "f6aedba32d584c6faf75fa3225b6bf11",
            "0335f4f45d064e5f8be6c30906b09b0f",
            "246f53a301c4489f9c57eb9b3e39dd2f",
            "06f6677a510e4e3ea8ba8e924461503e",
            "b90413f88e564f00bf8b1190ea73ff58",
            "f95a286d5cee46d690ca07b9e7c3b6cb",
            "e635752c03c04d789a3d94db9ed4e603",
            "be36fdf359794409853347922373edc9",
            "b98df13d501d4bddbb77fc7ba58aad55",
            "716bf734344f48a5b6e9dc95c67422e0",
            "37aa2a4ef7bf42808949a6a09b93c8ef",
            "12c2ecee99e44ee5a3bc024c2a9c2859",
            "46d5e1caeff2445c964994c2947efd25",
            "1d228e189c194afcacb0cc91d5b6590a",
            "25149f858b234d3a9e85549f4e7df96a",
            "5570700115fc4fb099846d69426791e5",
            "34244121210d4b16a1fbb17106e45ed9",
            "3200ad14a30540f783876589634e84ba",
            "a630d227f91b407aa72c4f98d3c4a7f6",
            "fb15fe9bef13483e829d24c1900825d5",
            "51a62829951341539d51c4847c8561c7",
            "70b80539e2d8419e80205dc7153ddc32",
            "f66d7d9671324ebf9cd6a69a2475173e",
            "edec976832b3421cba338ac9c89cbc09",
            "fcf24410353e434f8238696a3f57061c",
            "e9c188086b56455489d3f4bb80bca832",
            "4e7b8839a4f1473994f8116681ee830e",
            "b1f4be52f26147ccbd6aa4f6a00702de",
            "be26e1547e0547b886251b76086972a9",
            "9c951720ae514d4a967b1814361b59d8",
            "589610f2ece1472dbbee778ccad0b815",
            "06fb38dd7fb941cfb5fa41317387a1be",
            "ca36c6506cd64863b8a5bef76465183a",
            "49bfcb174fea4f8bb7a8fcf18dc187ec",
            "3616f9afddfd4c8c91bbc1a7592452d8",
            "bb0903a9eb554ff288f5e99a62197adb",
            "8833bc14b1624326be16687487640648",
            "b09b565d3dd3416686afa1a85621540e",
            "6f1609789eaf4266bc15a53c74a2ea7f",
            "4bcb69b7947f4d10b463d776aa4bf283",
            "b16dc4ab7c434886a722cd2814983c77",
            "f769c9fc17f8490f8a338c256904c065",
            "4f2f905ec3f24545a579f68509e301bd",
            "9983a9b380c445cd98cf6a317b1452a5",
            "96496008f76a438ea3d6bee4191bb5fa",
            "237fcf581cbf4fcc9ad8c2c8057227fb",
            "fd7c075a004a4b8297641d8f01ce4d33",
            "4df27cc27aa14c08bbb3e3f17cb815f8",
            "05b6090d9bfa4872b3af660894eb861c",
            "2d359af6f4a84f8ebc74bca762c81ef1",
            "072a8b41b81b47569004b9bc7b03067e",
            "b4421c9794e44588ad17740c52f8d149",
            "4c63a110553f4c9b83a0ca6f81f772d3",
            "20f788dea8694193810992c75de33f5c",
            "024b2879f714439eaf7bbd0e9a78ddd1",
            "f3d52e9e054a460791671e8164828296"
          ]
        },
        "id": "t52SxLmEHIU1",
        "outputId": "0ed11e5d-f7d7-46f2-aae1-ba206deb800f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/892 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f28247267e449d995902add98b7aa6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0335f4f45d064e5f8be6c30906b09b0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/406 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46d5e1caeff2445c964994c2947efd25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edec976832b3421cba338ac9c89cbc09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3616f9afddfd4c8c91bbc1a7592452d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "237fcf581cbf4fcc9ad8c2c8057227fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.NONE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V1UaquFDHNYc",
        "outputId": "b7f15325-58af-4f5e-8f8a-dbcdb56cdd28"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuated_text = model.restore_punctuation(transcript_joined)"
      ],
      "metadata": {
        "id": "3EAnCOZyIBY-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(punctuated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO_DGXQsIhPE",
        "outputId": "2b8362f0-3706-4613-d27b-272757e31017"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello everyone. I am Santi and I'm currently working as an ml engineer. today, we are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers. um, I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an ml job as soon as possible. okay, so, without any further Ado, let's Dive Right In. so our title is going to be um, so our project title is going to be, uh, YouTube video summarizer with llm. well, so what's going to do is going to take in a video and you can ask any question regarding the videos contents, the images, Etc. and that's going to be really really good, really useful as well, and that can be a mini deployed project as well. okay, so, first things, first. um, let's, let's, let's think about why do we need this in the first place? the interviewer might say: why not just use chat GPT? right, because chat gpg has now enabled the search web feature for every free user, right? so you might be wondering: why not just use that? okay, so let's see why we are not going to use that. as you can see, right here, we have our chat GPT open and let's see um, which video are we going to use? yeah, so this is a video that we are going to use. right here, as you can see my binary classification video, which is of the length of 32, 32 minutes. okay, so let's put this inside the chat GPD and I will the search web feature and say: write the transcript for this. this for this video, because, first of all, we'll need the transcript. right, as you can see, right here, it says that it's unable to actually get the video, um transcript. so if you don't have the transcript, obviously, then you won't be able to do anything with it. right, okay, whenever you get any project, it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily. this is very important because if you think that, how, how am I going to do that? we don't have this, we don't have that at the first. so this going to be very confusing. so let's tackle it one by one, step by step. remember this for any project that you are going to do. okay, I'm going to use Google collab here because we need GPU for our support. so if you don't have GPU on your system or you're using any Windows system, you're using a Mac system, whatever it is, it doesn't matter. as long as you have Google collab, you can just go in. it's free for you to use and you can do the project here and in your resume you can just put in link, okay, so let's do first install. let's first install the YouTube transcript API. great, now we have the YouTube trans transcript API. so now what we going to do is basically get the link, provide the link to the video um, to this library, and generate the transcript using this. now we're going to import the YouTube transcript API. so, from YouTube YouTube transcript API- sounds good. now let's get the video ID from the um video. so what we going to do is basically, as you know, this is the video right here and this is the video ID. so whenever you put in a link, you're going to get the video ID from here. get video ID is going to be this function. great, you now have the video ID. so let's see what the video ID looks like: um, copy this: yeah, this is the video ID. yeah, next thing is getting the transcript. so, basically, get video ID. we already have that, so let's just store it in a variable. this one going to be video ID. um, yeah, sounds good. now let's see what the transcript looks like. yeah, as you can see, this is what the transcript looks like. so now, what you're going to do is, uh, add all this together. yep, yeah, so now what we going to do is do the transcript join. so what does it going to look like? exactly? just join this together, all the text features that you have in this transcript. great, now we can see what the transcript joint looks like. yeah, great, as you can see right here, this is our transcript that we have. um, okay, as you can see, we have it, Santi, but we can't do anything about it, so let's just forget about it for the moment. yeah, um, sounds good. now, what we going to do is, basically, we need to, as you can see, the transcript that you saw. um, it does not actually have a proper punctuation, so we going to put in the punctuation. now, how we're going to do that? we're going to use a model for that. this is where the llm comes into the play, okay, so now, as you can see, like, uh, restoring the punctuation. this is called a library, which we have actually, and this is actually a restore Punk Library. yeah, this is our Punk library. that we have, actually. but there's a problem out here. the versions are very like old because it's three years ago. so that is why there's a patch for the Same by another, uh, GitHub user. so that that is what we are going to use here. great. so this is actually the thing. please note it down, because you're going to need this. if you use the normal ARB, it's not going to help, great. now the next thing comes is restoring the punctuations. so from the r pun, we going to import restore puns and then you're going to use this restore Punk function. so what this actually does behind the scenes is it uses a model from the hugging face library and this model is actually loaded here, and this model is actually pre-trained for taking in bunch of text and then, um, getting the punctu ation back to that text. great, now that this is done, let's move on to the um getting the results from the punctuation. so, as you can see right here, this one py toch model, this model actually got loaded. so one thing: if you facing some problem with GPU, it's very important to use this actually, um here. yeah, as you can see right here, we have GPU enable T4. so you need to enable the GPU in your um collab, otherwise you're going to get an error. that is, GPU is not available and it's not really possible to do this without GPU. you can do it with CPU as well, but it's going to be very slow, okay. so, now that you can see, we have loaded the model, we have gotten all this vocabulary, we have gotten the tokenizer, we have gotten the configuration and everything. so now we are ready to go. let's see the results. yeah, we are printing out the results, as you can see. yeah, this is, as you can see, it's like very good punctuation. I'm an algorithm: full stop. I've covered log likelihood, it, which is kind of a prerequisite- full stop. then, comma a: du, let start. it's pretty good. not um 100% accurate, because it's not a very good model, but it's pretty good. we are going to use this, okay. so the next thing that we're going to do is um, we're going to use the chat, GPT free version, API version to get the results from this transcript. so, as you can see, we have the transcript right here, so we know the entire content of the video. so it's going to be piece of cake for now sounds good. yeah, so let's see. we going to import open AI. as you can see, I've already install open a. if you have not, then you can do it using not equal to pip. install open AI to the open AI API key website. yeah, as you can see right here, this has API key. you can just log in. yeah, you can just log in. here's my API key. you can't see that. just create a new secret key, write the key permissions all. create secret key and you have the API key right here. it's a. it's. it's very easy. sounds good. now, now we have the API key, now we are having the prompt, so let's have the prompt here. so, as you can see right here, let's go over this. so from open, we importing open. then we have the client with the API key. just now we set and now this is the. remember this. this is very, very easy and this is like very standard thing that we going to do. so this is the way you have to access the uh openai API. so we have the message here. roll user content prompt. so this is the prompt that we going to pass in um and then we are going to use a model- GPT 3.5 turbo, because the other GPD models are all paid. we're not going to use a paid version, we're going to use the free version. and we have the temperature set equal to one. it controls a Randomness, basically Max tokens: 2- 56 is the maximum number of tokens in the response. um top P equal to 1, which means the op is a nuclear sampling parameter, which is just another thing. for uh, like temperature, just like temperature. we we are determining the one with the higher probability. Mass um. frequency penalty is basically zero, which means that we don't want the model to repeat anything, and prence penalty is also zero, which means that we do not want it to add unnecessary words or just making it for veros without any reason. for example, if you're asking for one word, just reply with one word. don't be any like verbos and explain why you're saying that and all that. you don't want that, right, um. so let's run this. great, now we have the response right here. simple thing, just print it out. so this is the way you can print out. the response is very important. chat completion choices z- message content. this is the way it actually comes in. so if you want to see what the chat completion looks like, you can check it out. it's actually kind of a dictionary, uh, it's kind of a class here where you have different attributes. so this is the content that we want, um, so that is why we are doing this. so let's see the content. so the test discusses the derivation and maths focusing on binary classification: perfect destion, boundary, uh, like likelihood function, sigmoid function, gradient, descent, optimal parameters, like Theta. it controls by discussing how to determine the equation in theeta, transpose X, comprehensive explanation and its implementation. so well, it's your cue to go and study this classification um video as well. but, yeah, you can do it at your own pace, but it's a very important thing as well. sorry, not sorry, a little bit of promotion, but yeah, now we done so. now you can just take on a prompt, which is any kind of prompt that you want. uh, why don't? why just change this? let's just have this one right here. so let's change it to: I don't know anything you want maybe um answer questions based on this text you have right here. so let's add a question. um, what do you want me to add? let's say what is classification? what is exactly taught here? let's see what it has to say. algorithm, predict the class speaker. well, it's not my name, but whatever we have put it in the transcript. so derivation and math, specifically binary classification- uh, okay, my gender is also wrong, but whatever decision, boundary and then dering the- this one radiant descent see, is perfect. the answer is perfect. key Concepts: it, um and steps involving binary classification: retailed description. as you can see, this is extremely good um. I also show you how you can deploy this from n to end, but that's for another video. okay, take care, bye.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RyOOYjhI1J5",
        "outputId": "627f2e35-5c78-4b70-928e-2e5e55970e74"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.29.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "# ✅ Use your actual API key here\n",
        "api_key_groq = userdata.get('GROQ_YOUTUBE_COLLAB')\n",
        "\n",
        "client = Groq(api_key=api_key_groq)\n",
        "\n",
        "# Make a request\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print response\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBpqpyKoKOpz",
        "outputId": "62e6bac6-d99b-4a62-cb70-55ddddcc7738"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to help you. How can I assist you today? Do you have a specific question, task, or topic you'd like to discuss? I'm here to listen and provide information to help you achieve your goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'\"Answer based on this paragraph: \\n text = \"{punctuated_text}. What is generally taught here?'"
      ],
      "metadata": {
        "id": "nfU_yM8jKR7C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfITOLRXnOD9",
        "outputId": "ea0668d9-7816-41d3-fe5b-492122001d63"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Summarize this text: \n",
            " text = \"hello everyone. I am Santi and I'm currently working as an ml engineer. today, we are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers. um, I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an ml job as soon as possible. okay, so, without any further Ado, let's Dive Right In. so our title is going to be um, so our project title is going to be, uh, YouTube video summarizer with llm. well, so what's going to do is going to take in a video and you can ask any question regarding the videos contents, the images, Etc. and that's going to be really really good, really useful as well, and that can be a mini deployed project as well. okay, so, first things, first. um, let's, let's, let's think about why do we need this in the first place? the interviewer might say: why not just use chat GPT? right, because chat gpg has now enabled the search web feature for every free user, right? so you might be wondering: why not just use that? okay, so let's see why we are not going to use that. as you can see, right here, we have our chat GPT open and let's see um, which video are we going to use? yeah, so this is a video that we are going to use. right here, as you can see my binary classification video, which is of the length of 32, 32 minutes. okay, so let's put this inside the chat GPD and I will the search web feature and say: write the transcript for this. this for this video, because, first of all, we'll need the transcript. right, as you can see, right here, it says that it's unable to actually get the video, um transcript. so if you don't have the transcript, obviously, then you won't be able to do anything with it. right, okay, whenever you get any project, it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily. this is very important because if you think that, how, how am I going to do that? we don't have this, we don't have that at the first. so this going to be very confusing. so let's tackle it one by one, step by step. remember this for any project that you are going to do. okay, I'm going to use Google collab here because we need GPU for our support. so if you don't have GPU on your system or you're using any Windows system, you're using a Mac system, whatever it is, it doesn't matter. as long as you have Google collab, you can just go in. it's free for you to use and you can do the project here and in your resume you can just put in link, okay, so let's do first install. let's first install the YouTube transcript API. great, now we have the YouTube trans transcript API. so now what we going to do is basically get the link, provide the link to the video um, to this library, and generate the transcript using this. now we're going to import the YouTube transcript API. so, from YouTube YouTube transcript API- sounds good. now let's get the video ID from the um video. so what we going to do is basically, as you know, this is the video right here and this is the video ID. so whenever you put in a link, you're going to get the video ID from here. get video ID is going to be this function. great, you now have the video ID. so let's see what the video ID looks like: um, copy this: yeah, this is the video ID. yeah, next thing is getting the transcript. so, basically, get video ID. we already have that, so let's just store it in a variable. this one going to be video ID. um, yeah, sounds good. now let's see what the transcript looks like. yeah, as you can see, this is what the transcript looks like. so now, what you're going to do is, uh, add all this together. yep, yeah, so now what we going to do is do the transcript join. so what does it going to look like? exactly? just join this together, all the text features that you have in this transcript. great, now we can see what the transcript joint looks like. yeah, great, as you can see right here, this is our transcript that we have. um, okay, as you can see, we have it, Santi, but we can't do anything about it, so let's just forget about it for the moment. yeah, um, sounds good. now, what we going to do is, basically, we need to, as you can see, the transcript that you saw. um, it does not actually have a proper punctuation, so we going to put in the punctuation. now, how we're going to do that? we're going to use a model for that. this is where the llm comes into the play, okay, so now, as you can see, like, uh, restoring the punctuation. this is called a library, which we have actually, and this is actually a restore Punk Library. yeah, this is our Punk library. that we have, actually. but there's a problem out here. the versions are very like old because it's three years ago. so that is why there's a patch for the Same by another, uh, GitHub user. so that that is what we are going to use here. great. so this is actually the thing. please note it down, because you're going to need this. if you use the normal ARB, it's not going to help, great. now the next thing comes is restoring the punctuations. so from the r pun, we going to import restore puns and then you're going to use this restore Punk function. so what this actually does behind the scenes is it uses a model from the hugging face library and this model is actually loaded here, and this model is actually pre-trained for taking in bunch of text and then, um, getting the punctu ation back to that text. great, now that this is done, let's move on to the um getting the results from the punctuation. so, as you can see right here, this one py toch model, this model actually got loaded. so one thing: if you facing some problem with GPU, it's very important to use this actually, um here. yeah, as you can see right here, we have GPU enable T4. so you need to enable the GPU in your um collab, otherwise you're going to get an error. that is, GPU is not available and it's not really possible to do this without GPU. you can do it with CPU as well, but it's going to be very slow, okay. so, now that you can see, we have loaded the model, we have gotten all this vocabulary, we have gotten the tokenizer, we have gotten the configuration and everything. so now we are ready to go. let's see the results. yeah, we are printing out the results, as you can see. yeah, this is, as you can see, it's like very good punctuation. I'm an algorithm: full stop. I've covered log likelihood, it, which is kind of a prerequisite- full stop. then, comma a: du, let start. it's pretty good. not um 100% accurate, because it's not a very good model, but it's pretty good. we are going to use this, okay. so the next thing that we're going to do is um, we're going to use the chat, GPT free version, API version to get the results from this transcript. so, as you can see, we have the transcript right here, so we know the entire content of the video. so it's going to be piece of cake for now sounds good. yeah, so let's see. we going to import open AI. as you can see, I've already install open a. if you have not, then you can do it using not equal to pip. install open AI to the open AI API key website. yeah, as you can see right here, this has API key. you can just log in. yeah, you can just log in. here's my API key. you can't see that. just create a new secret key, write the key permissions all. create secret key and you have the API key right here. it's a. it's. it's very easy. sounds good. now, now we have the API key, now we are having the prompt, so let's have the prompt here. so, as you can see right here, let's go over this. so from open, we importing open. then we have the client with the API key. just now we set and now this is the. remember this. this is very, very easy and this is like very standard thing that we going to do. so this is the way you have to access the uh openai API. so we have the message here. roll user content prompt. so this is the prompt that we going to pass in um and then we are going to use a model- GPT 3.5 turbo, because the other GPD models are all paid. we're not going to use a paid version, we're going to use the free version. and we have the temperature set equal to one. it controls a Randomness, basically Max tokens: 2- 56 is the maximum number of tokens in the response. um top P equal to 1, which means the op is a nuclear sampling parameter, which is just another thing. for uh, like temperature, just like temperature. we we are determining the one with the higher probability. Mass um. frequency penalty is basically zero, which means that we don't want the model to repeat anything, and prence penalty is also zero, which means that we do not want it to add unnecessary words or just making it for veros without any reason. for example, if you're asking for one word, just reply with one word. don't be any like verbos and explain why you're saying that and all that. you don't want that, right, um. so let's run this. great, now we have the response right here. simple thing, just print it out. so this is the way you can print out. the response is very important. chat completion choices z- message content. this is the way it actually comes in. so if you want to see what the chat completion looks like, you can check it out. it's actually kind of a dictionary, uh, it's kind of a class here where you have different attributes. so this is the content that we want, um, so that is why we are doing this. so let's see the content. so the test discusses the derivation and maths focusing on binary classification: perfect destion, boundary, uh, like likelihood function, sigmoid function, gradient, descent, optimal parameters, like Theta. it controls by discussing how to determine the equation in theeta, transpose X, comprehensive explanation and its implementation. so well, it's your cue to go and study this classification um video as well. but, yeah, you can do it at your own pace, but it's a very important thing as well. sorry, not sorry, a little bit of promotion, but yeah, now we done so. now you can just take on a prompt, which is any kind of prompt that you want. uh, why don't? why just change this? let's just have this one right here. so let's change it to: I don't know anything you want maybe um answer questions based on this text you have right here. so let's add a question. um, what do you want me to add? let's say what is classification? what is exactly taught here? let's see what it has to say. algorithm, predict the class speaker. well, it's not my name, but whatever we have put it in the transcript. so derivation and math, specifically binary classification- uh, okay, my gender is also wrong, but whatever decision, boundary and then dering the- this one radiant descent see, is perfect. the answer is perfect. key Concepts: it, um and steps involving binary classification: retailed description. as you can see, this is extremely good um. I also show you how you can deploy this from n to end, but that's for another video. okay, take care, bye.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(punctuated_text))\n",
        "print(len(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTmhSCYUo_Dz",
        "outputId": "7548667f-22f4-4531-9622-6f2b7a2166be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11007\n",
            "11039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGDRB_w7pLew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7a13d6a",
        "outputId": "75919fd2-1e9d-4912-d02f-329fab8d98a6"
      },
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the paragraph, the topic that is generally taught here is binary classification, specifically the derivation and math related to binary classification, which includes concepts such as likelihood function, sigmoid function, gradient descent, optimal parameters, and how to determine the equation in Theta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLvhL-x9vdu4",
        "outputId": "2f84ec3d-17cf-476e-91ad-c089b7f6c3ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rkqeoTOfvlHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}